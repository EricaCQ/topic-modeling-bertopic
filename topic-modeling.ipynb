{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b9c13b-b5c7-4f1d-ace1-a16222518c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a016690-4e40-427a-be75-f868e94b1b28",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb089b31-9655-4f8f-80ef-65d87d9b87bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ba847d-4055-4833-b5c3-98c6f04923fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the labeled training dataset from CSV\n",
    "\n",
    "df_train = pd.read_csv(\"dataset_llm_judge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a5da68-469f-4c4e-8be8-f3e82e76ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the validation dataset with custom settings to handle formatting\n",
    "\n",
    "df_valid = pd.read_csv(\"dataset_valid.csv\",\n",
    "    sep=\"|\",\n",
    "    engine=\"python\",\n",
    "    header=None,\n",
    "    names=[\"id\", \"text\"],\n",
    "    quoting=3,            # ignoring quotes\n",
    "    on_bad_lines=\"warn\",  # warning about bad lines\n",
    "    encoding=\"utf-8\"      # allowing to switch to latin1 if there are encoding issues\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f78dc95-369a-4821-a97a-6fef87ddc293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Due to an unexpected nltk bug, we decided to apply re to a small set of stopwords\n",
    "stop_words = set([\n",
    "    \"the\", \"and\", \"is\", \"to\", \"of\", \"in\", \"that\", \"for\", \"it\", \"on\", \"with\",\n",
    "    \"as\", \"was\", \"at\", \"by\", \"an\", \"be\", \"this\", \"are\", \"from\", \"had\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0541c44a-37e9-4bbc-9294-417af7a63a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = re.findall(r'\\b[a-z]{2,}\\b', text)  # pega palavras com 2+ letras\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e14de7a8-960a-4b91-84e6-c446bd0715bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"clean_text\"] = df_train[\"text\"].astype(str).apply(clean_text)\n",
    "df_valid[\"clean_text\"] = df_valid[\"text\"].astype(str).apply(clean_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b27f1b-aacc-4ac9-93e8-4a1bc1042502",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = df_train[\"clean_text\"].astype(str).tolist()\n",
    "valid_texts = df_valid[\"clean_text\"].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdae6dd-20c2-45ca-a066-3cc67ecd9161",
   "metadata": {},
   "source": [
    "### Training Model with BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61327193-857b-4fb1-8576-7ddff52c60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and applying BERTopic model\n",
    "# Training with training data\n",
    "topic_model = BERTopic()\n",
    "# Applying model to validated data\n",
    "train_topics, train_probs = topic_model.fit_transform(train_texts)\n",
    "# Showing most relevant topics\n",
    "valid_topics, valid_probs = topic_model.transform(valid_texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21af3aaa-a358-4d55-ac27-177b2c30a811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>194</td>\n",
       "      <td>-1_food_but_they_my</td>\n",
       "      <td>[food, but, they, my, not, all, we, you, were,...</td>\n",
       "      <td>[have reservations about all you can eat deal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0_lobster_fish_fresh_salads</td>\n",
       "      <td>[lobster, fish, fresh, salads, food, delicious...</td>\n",
       "      <td>[fish so very fresh, only things could really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>1_service_food_waiter_rude</td>\n",
       "      <td>[service, food, waiter, rude, me, waitress, we...</td>\n",
       "      <td>[waitress moved our table practically into bat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>2_place_loved_spot_have</td>\n",
       "      <td>[place, loved, spot, have, fun, friends, there...</td>\n",
       "      <td>[place small intimate you may feel little crow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3_service_slow_wait_friendly</td>\n",
       "      <td>[service, slow, wait, friendly, prompt, staff,...</td>\n",
       "      <td>[but service bit slow, service prompt friendly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>4_restaurant_decor_night_looking</td>\n",
       "      <td>[restaurant, decor, night, looking, small, pla...</td>\n",
       "      <td>[small cute restaurant, decor night tho but th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>5_back_again_will_go</td>\n",
       "      <td>[back, again, will, go, going, would, ll, defi...</td>\n",
       "      <td>[will back, we go back again, we will never go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>6_sushi_japanese_rolls_mizu</td>\n",
       "      <td>[sushi, japanese, rolls, mizu, all, sashimi, e...</td>\n",
       "      <td>[boring inside our sushi pretty below average ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>7_gem_we_wrong_pleasantly</td>\n",
       "      <td>[gem, we, wrong, pleasantly, surprised, red, w...</td>\n",
       "      <td>[you can not go wrong red eye grill, when we s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>8_food_good_great_excellent</td>\n",
       "      <td>[food, good, great, excellent, nothing, minnow...</td>\n",
       "      <td>[food great, food very good well considering w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>9_pizza_crust_ingredients_cheese</td>\n",
       "      <td>[pizza, crust, ingredients, cheese, use, even,...</td>\n",
       "      <td>[pizza only pizza nyc should not have addition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>10_york_new_ny_manhattan</td>\n",
       "      <td>[york, new, ny, manhattan, midtown, became, sh...</td>\n",
       "      <td>[authentic shanghai style can not recommend be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>11_ambience_atmosphere_so_wonderful</td>\n",
       "      <td>[ambience, atmosphere, so, wonderful, service,...</td>\n",
       "      <td>[highly recommend cafe st bart their food ambi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>12_prices_worth_felt_also</td>\n",
       "      <td>[prices, worth, felt, also, moderate, aware, t...</td>\n",
       "      <td>[atmosphere greatest but suppose how they keep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>13_menu_wine_appetizer_list</td>\n",
       "      <td>[menu, wine, appetizer, list, great, caviar, f...</td>\n",
       "      <td>[two complaints their appetizer selection stin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>14_wine_list_selection_glass</td>\n",
       "      <td>[wine, list, selection, glass, well, interesti...</td>\n",
       "      <td>[drinks always well made wine selection fairly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>15_thai_planet_pad_sweet</td>\n",
       "      <td>[thai, planet, pad, sweet, ordered, too, avera...</td>\n",
       "      <td>[planet thailand has always been hit me go the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                 Name  \\\n",
       "0      -1    194                  -1_food_but_they_my   \n",
       "1       0     68          0_lobster_fish_fresh_salads   \n",
       "2       1     57           1_service_food_waiter_rude   \n",
       "3       2     51              2_place_loved_spot_have   \n",
       "4       3     32         3_service_slow_wait_friendly   \n",
       "5       4     31     4_restaurant_decor_night_looking   \n",
       "6       5     28                 5_back_again_will_go   \n",
       "7       6     24          6_sushi_japanese_rolls_mizu   \n",
       "8       7     24            7_gem_we_wrong_pleasantly   \n",
       "9       8     24          8_food_good_great_excellent   \n",
       "10      9     21     9_pizza_crust_ingredients_cheese   \n",
       "11     10     18             10_york_new_ny_manhattan   \n",
       "12     11     18  11_ambience_atmosphere_so_wonderful   \n",
       "13     12     17            12_prices_worth_felt_also   \n",
       "14     13     17          13_menu_wine_appetizer_list   \n",
       "15     14     15         14_wine_list_selection_glass   \n",
       "16     15     12             15_thai_planet_pad_sweet   \n",
       "\n",
       "                                       Representation  \\\n",
       "0   [food, but, they, my, not, all, we, you, were,...   \n",
       "1   [lobster, fish, fresh, salads, food, delicious...   \n",
       "2   [service, food, waiter, rude, me, waitress, we...   \n",
       "3   [place, loved, spot, have, fun, friends, there...   \n",
       "4   [service, slow, wait, friendly, prompt, staff,...   \n",
       "5   [restaurant, decor, night, looking, small, pla...   \n",
       "6   [back, again, will, go, going, would, ll, defi...   \n",
       "7   [sushi, japanese, rolls, mizu, all, sashimi, e...   \n",
       "8   [gem, we, wrong, pleasantly, surprised, red, w...   \n",
       "9   [food, good, great, excellent, nothing, minnow...   \n",
       "10  [pizza, crust, ingredients, cheese, use, even,...   \n",
       "11  [york, new, ny, manhattan, midtown, became, sh...   \n",
       "12  [ambience, atmosphere, so, wonderful, service,...   \n",
       "13  [prices, worth, felt, also, moderate, aware, t...   \n",
       "14  [menu, wine, appetizer, list, great, caviar, f...   \n",
       "15  [wine, list, selection, glass, well, interesti...   \n",
       "16  [thai, planet, pad, sweet, ordered, too, avera...   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [have reservations about all you can eat deal ...  \n",
       "1   [fish so very fresh, only things could really ...  \n",
       "2   [waitress moved our table practically into bat...  \n",
       "3   [place small intimate you may feel little crow...  \n",
       "4   [but service bit slow, service prompt friendly...  \n",
       "5   [small cute restaurant, decor night tho but th...  \n",
       "6   [will back, we go back again, we will never go...  \n",
       "7   [boring inside our sushi pretty below average ...  \n",
       "8   [you can not go wrong red eye grill, when we s...  \n",
       "9   [food great, food very good well considering w...  \n",
       "10  [pizza only pizza nyc should not have addition...  \n",
       "11  [authentic shanghai style can not recommend be...  \n",
       "12  [highly recommend cafe st bart their food ambi...  \n",
       "13  [atmosphere greatest but suppose how they keep...  \n",
       "14  [two complaints their appetizer selection stin...  \n",
       "15  [drinks always well made wine selection fairly...  \n",
       "16  [planet thailand has always been hit me go the...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95e58fb2-4096-496d-8fe4-9491f3a2b30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: lobster, fish, fresh, salads, food\n",
      "Topic 1: service, food, waiter, rude, me\n",
      "Topic 2: place, loved, spot, have, fun\n",
      "Topic 3: service, slow, wait, friendly, prompt\n",
      "Topic 4: restaurant, decor, night, looking, small\n",
      "Topic 5: back, again, will, go, going\n",
      "Topic 6: sushi, japanese, rolls, mizu, all\n",
      "Topic 7: gem, we, wrong, pleasantly, surprised\n",
      "Topic 8: food, good, great, excellent, nothing\n",
      "Topic 9: pizza, crust, ingredients, cheese, use\n",
      "Topic 10: york, new, ny, manhattan, midtown\n",
      "Topic 11: ambience, atmosphere, so, wonderful, service\n",
      "Topic 12: prices, worth, felt, also, moderate\n",
      "Topic 13: menu, wine, appetizer, list, great\n",
      "Topic 14: wine, list, selection, glass, well\n",
      "Topic 15: thai, planet, pad, sweet, ordered\n"
     ]
    }
   ],
   "source": [
    "# Generating Topic Textual data\n",
    "\n",
    "for topic_id in topic_model.get_topics().keys():\n",
    "    if topic_id == -1:\n",
    "        continue  # Pula o outlier (tópico -1)\n",
    "    \n",
    "    topic_words = topic_model.get_topic(topic_id)\n",
    "\n",
    "    # Garante que é uma lista válida\n",
    "    if isinstance(topic_words, list):\n",
    "        top_words = \", \".join([word for word, _ in topic_words[:5]])\n",
    "        print(f\"Topic {topic_id}: {top_words}\")\n",
    "    else:\n",
    "        print(f\"Topic {topic_id}:error extracting keywords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ac4278-dbde-4a02-b2bf-e45a0a8d894f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365527a9-9a81-4f53-9a20-efa89336f6af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4084c819-16ca-4a3f-86e1-22359bda1d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98058bd7-5e0d-4abb-a840-6dd33e7cd66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
